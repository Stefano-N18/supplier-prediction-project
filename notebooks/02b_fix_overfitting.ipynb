{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f59039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOLUCIONES PARA OVERFITTING EXTREMO\n",
      "==================================================\n",
      "SOLUCIÓN 1: ELIMINAR FEATURES PROBLEMÁTICAS\n",
      "----------------------------------------\n",
      "Features eliminadas: ['country', 'quality_rating']\n",
      "Features utilizadas: ['price_usd', 'delivery_days', 'payment_terms_days', 'shipping_included', 'express_available', 'order_urgency', 'quantity_needed', 'budget_available', 'product_type', 'incoterms', 'month', 'quarter']\n",
      "\n",
      "SOLUCIÓN 2: PARÁMETROS ULTRA-CONSERVADORES\n",
      "----------------------------------------\n",
      "Accuracy modelo conservador: 0.898\n",
      "Profundidad: 3\n",
      "Número de hojas: 7\n",
      "\n",
      "SOLUCIÓN 3: VALIDACIÓN CRUZADA\n",
      "----------------------------------------\n",
      "CV Scores: [0.89711934 0.90082645 0.90082645 0.89669421 0.89669421]\n",
      "CV Mean: 0.898 ± 0.002\n",
      "✅ Variabilidad aceptable entre folds\n",
      "\n",
      "SOLUCIÓN 4: AÑADIR RUIDO PARA REDUCIR OVERFITTING\n",
      "----------------------------------------\n",
      "Ruido añadido a features numéricas\n",
      "Accuracy modelo con ruido: 0.887\n",
      "\n",
      "SOLUCIÓN 5: ENSEMBLE DE MODELOS SIMPLES\n",
      "----------------------------------------\n",
      "Accuracy Random Forest conservador: 1.000\n",
      "\n",
      "Importancia de features (Random Forest):\n",
      "              feature  importance\n",
      "1       delivery_days    0.222629\n",
      "4   express_available    0.200694\n",
      "9           incoterms    0.157393\n",
      "7    budget_available    0.099211\n",
      "3   shipping_included    0.080337\n",
      "8        product_type    0.072635\n",
      "0           price_usd    0.070549\n",
      "2  payment_terms_days    0.068979\n",
      "\n",
      "SOLUCIÓN 6: VALIDACIÓN TEMPORAL\n",
      "----------------------------------------\n",
      "Train temporal: 2022-01-01 00:00:00 a 2024-06-02 00:00:00\n",
      "Test temporal: 2024-06-02 00:00:00 a 2024-12-31 00:00:00\n",
      "Accuracy validación temporal: 0.909\n",
      "\n",
      "==================================================\n",
      "RESUMEN DE SOLUCIONES Y RESULTADOS:\n",
      "==================================================\n",
      "Modelo conservador (sin country/quality): 0.898 ⚠️  REVISAR\n",
      "Modelo con ruido: 0.887 ⚠️  REVISAR\n",
      "Random Forest conservador: 1.000 ⚠️  REVISAR\n",
      "Validación temporal: 0.909 ⚠️  REVISAR\n",
      "\n",
      "RECOMENDACIONES FINALES:\n",
      "1. USA el modelo conservador sin country/quality_rating\n",
      "2. Accuracy objetivo: 0.50-0.70 para 6 proveedores\n",
      "3. Prefiere modelos simples y interpretables\n",
      "4. Valida siempre con datos temporales\n",
      "5. Si accuracy > 0.80, sospecha de overfitting\n",
      "\n",
      "MODELO RECOMENDADO PARA PRODUCCIÓN:\n",
      "----------------------------------------\n",
      "Accuracy modelo final: 0.739\n",
      "Profundidad: 3\n",
      "\n",
      "✅ Modelo corregido guardado en ../models/*_fixed.pkl\n",
      "✅ Listo para usar en sistema de recomendación\n"
     ]
    }
   ],
   "source": [
    "# SOLUCIONES PARA OVERFITTING EXTREMO\n",
    "# Ejecuta estas soluciones paso a paso\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"SOLUCIONES PARA OVERFITTING EXTREMO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('../data/dewatering_realistic_supplier_dataset.csv')\n",
    "\n",
    "# SOLUCIÓN 1: ELIMINAR FEATURES QUE CAUSAN DATA LEAKAGE\n",
    "print(\"SOLUCIÓN 1: ELIMINAR FEATURES PROBLEMÁTICAS\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Features originales problemáticas\n",
    "problematic_features = ['country', 'quality_rating']  # Estas identifican directamente al proveedor\n",
    "\n",
    "# Features limpias (sin data leakage obvio)\n",
    "clean_features = [\n",
    "    'price_usd', \n",
    "    'delivery_days',\n",
    "    'payment_terms_days', \n",
    "    'shipping_included',\n",
    "    'express_available',\n",
    "    'order_urgency',\n",
    "    'quantity_needed',\n",
    "    'budget_available',\n",
    "    'product_type',\n",
    "    'incoterms',\n",
    "    'month',\n",
    "    'quarter'\n",
    "]\n",
    "\n",
    "print(f\"Features eliminadas: {problematic_features}\")\n",
    "print(f\"Features utilizadas: {clean_features}\")\n",
    "\n",
    "# Preparar datos limpios\n",
    "X_clean = df[clean_features].copy()\n",
    "y = df['supplier_name'].copy()\n",
    "\n",
    "# Encoding\n",
    "label_encoders = {}\n",
    "categorical_features = ['order_urgency', 'product_type', 'incoterms', 'quarter']\n",
    "\n",
    "for feature in categorical_features:\n",
    "    if feature in X_clean.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_clean[feature] = le.fit_transform(X_clean[feature].astype(str))\n",
    "        label_encoders[feature] = le\n",
    "\n",
    "# Convertir booleanos\n",
    "boolean_features = ['shipping_included', 'express_available']\n",
    "for feature in boolean_features:\n",
    "    if feature in X_clean.columns:\n",
    "        X_clean[feature] = X_clean[feature].astype(int)\n",
    "\n",
    "# Encoder para target\n",
    "target_encoder = LabelEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y)\n",
    "\n",
    "# SOLUCIÓN 2: MODELO MUY RESTRICTIVO\n",
    "print(f\"\\nSOLUCIÓN 2: PARÁMETROS ULTRA-CONSERVADORES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_clean, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Modelo ultra-restrictivo\n",
    "conservative_model = DecisionTreeClassifier(\n",
    "    max_depth=3,              # MUY bajo\n",
    "    min_samples_split=50,     # ALTO (mínimo 50 muestras para dividir)\n",
    "    min_samples_leaf=20,      # ALTO (mínimo 20 muestras por hoja)\n",
    "    max_features=5,           # Máximo 5 features por división\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "conservative_model.fit(X_train, y_train)\n",
    "y_pred_conservative = conservative_model.predict(X_test)\n",
    "accuracy_conservative = accuracy_score(y_test, y_pred_conservative)\n",
    "\n",
    "print(f\"Accuracy modelo conservador: {accuracy_conservative:.3f}\")\n",
    "print(f\"Profundidad: {conservative_model.get_depth()}\")\n",
    "print(f\"Número de hojas: {conservative_model.get_n_leaves()}\")\n",
    "\n",
    "# SOLUCIÓN 3: VALIDACIÓN CRUZADA PARA VERIFICAR ESTABILIDAD\n",
    "print(f\"\\nSOLUCIÓN 3: VALIDACIÓN CRUZADA\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cv_scores = cross_val_score(conservative_model, X_clean, y_encoded, cv=5, scoring='accuracy')\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"CV Mean: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "\n",
    "if cv_scores.std() > 0.1:\n",
    "    print(\"⚠️  Alta variabilidad entre folds - modelo inestable\")\n",
    "else:\n",
    "    print(\"✅ Variabilidad aceptable entre folds\")\n",
    "\n",
    "# SOLUCIÓN 4: AÑADIR RUIDO A LOS DATOS\n",
    "print(f\"\\nSOLUCIÓN 4: AÑADIR RUIDO PARA REDUCIR OVERFITTING\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Crear copia con ruido\n",
    "X_noisy = X_clean.copy()\n",
    "\n",
    "# Añadir ruido gaussiano a features numéricas\n",
    "numeric_features = ['price_usd', 'delivery_days', 'payment_terms_days', 'quantity_needed', 'budget_available']\n",
    "noise_factor = 0.05  # 5% de ruido\n",
    "\n",
    "for feature in numeric_features:\n",
    "    if feature in X_noisy.columns:\n",
    "        std_dev = X_noisy[feature].std()\n",
    "        noise = np.random.normal(0, std_dev * noise_factor, len(X_noisy))\n",
    "        X_noisy[feature] = X_noisy[feature] + noise\n",
    "\n",
    "print(\"Ruido añadido a features numéricas\")\n",
    "\n",
    "# Entrenar con datos ruidosos\n",
    "X_train_noisy, X_test_noisy, y_train_noisy, y_test_noisy = train_test_split(\n",
    "    X_noisy, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "noisy_model = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "noisy_model.fit(X_train_noisy, y_train_noisy)\n",
    "y_pred_noisy = noisy_model.predict(X_test_noisy)\n",
    "accuracy_noisy = accuracy_score(y_test_noisy, y_pred_noisy)\n",
    "\n",
    "print(f\"Accuracy modelo con ruido: {accuracy_noisy:.3f}\")\n",
    "\n",
    "# SOLUCIÓN 5: MODELO ENSEMBLE SIMPLE\n",
    "print(f\"\\nSOLUCIÓN 5: ENSEMBLE DE MODELOS SIMPLES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest muy conservador\n",
    "rf_conservative = RandomForestClassifier(\n",
    "    n_estimators=10,          # Pocos árboles\n",
    "    max_depth=3,              # Muy poco profundo\n",
    "    min_samples_split=50,     # Restrictivo\n",
    "    min_samples_leaf=20,      # Restrictivo\n",
    "    max_features=3,           # Pocas features por árbol\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_conservative.fit(X_train, y_train)\n",
    "y_pred_rf = rf_conservative.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Accuracy Random Forest conservador: {accuracy_rf:.3f}\")\n",
    "\n",
    "# Feature importance del RF\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X_clean.columns,\n",
    "    'importance': rf_conservative.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"\\nImportancia de features (Random Forest):\")\n",
    "print(rf_importance.head(8))\n",
    "\n",
    "# SOLUCIÓN 6: VALIDACIÓN TEMPORAL\n",
    "print(f\"\\nSOLUCIÓN 6: VALIDACIÓN TEMPORAL\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Ordenar por fecha\n",
    "df_temporal = df.copy()\n",
    "df_temporal['date'] = pd.to_datetime(df_temporal['date'])\n",
    "df_temporal = df_temporal.sort_values('date')\n",
    "\n",
    "# División temporal: 80% más antiguo para train, 20% más reciente para test\n",
    "split_idx = int(len(df_temporal) * 0.8)\n",
    "train_temporal = df_temporal.iloc[:split_idx]\n",
    "test_temporal = df_temporal.iloc[split_idx:]\n",
    "\n",
    "print(f\"Train temporal: {train_temporal['date'].min()} a {train_temporal['date'].max()}\")\n",
    "print(f\"Test temporal: {test_temporal['date'].min()} a {test_temporal['date'].max()}\")\n",
    "\n",
    "# Preparar datos temporales\n",
    "X_train_temp = train_temporal[clean_features].copy()\n",
    "X_test_temp = test_temporal[clean_features].copy()\n",
    "y_train_temp = train_temporal['supplier_name'].copy()\n",
    "y_test_temp = test_temporal['supplier_name'].copy()\n",
    "\n",
    "# Encoding temporal\n",
    "for feature in categorical_features:\n",
    "    if feature in X_train_temp.columns:\n",
    "        le = LabelEncoder()\n",
    "        X_train_temp[feature] = le.fit_transform(X_train_temp[feature].astype(str))\n",
    "        # Para test, manejar categorías no vistas\n",
    "        X_test_temp[feature] = X_test_temp[feature].astype(str)\n",
    "        X_test_temp[feature] = X_test_temp[feature].apply(\n",
    "            lambda x: le.transform([x])[0] if x in le.classes_ else 0\n",
    "        )\n",
    "\n",
    "for feature in boolean_features:\n",
    "    if feature in X_train_temp.columns:\n",
    "        X_train_temp[feature] = X_train_temp[feature].astype(int)\n",
    "        X_test_temp[feature] = X_test_temp[feature].astype(int)\n",
    "\n",
    "# Encoding de targets\n",
    "y_train_temp_encoded = target_encoder.fit_transform(y_train_temp)\n",
    "y_test_temp_encoded = target_encoder.transform(y_test_temp)\n",
    "\n",
    "# Modelo temporal\n",
    "temporal_model = DecisionTreeClassifier(\n",
    "    max_depth=4,\n",
    "    min_samples_split=40,\n",
    "    min_samples_leaf=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "temporal_model.fit(X_train_temp, y_train_temp_encoded)\n",
    "y_pred_temporal = temporal_model.predict(X_test_temp)\n",
    "accuracy_temporal = accuracy_score(y_test_temp_encoded, y_pred_temporal)\n",
    "\n",
    "print(f\"Accuracy validación temporal: {accuracy_temporal:.3f}\")\n",
    "\n",
    "# RESUMEN DE RESULTADOS\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"RESUMEN DE SOLUCIONES Y RESULTADOS:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "results = [\n",
    "    (\"Modelo conservador (sin country/quality)\", accuracy_conservative),\n",
    "    (\"Modelo con ruido\", accuracy_noisy),\n",
    "    (\"Random Forest conservador\", accuracy_rf),\n",
    "    (\"Validación temporal\", accuracy_temporal)\n",
    "]\n",
    "\n",
    "for description, acc in results:\n",
    "    status = \"✅ BUENO\" if 0.4 <= acc <= 0.8 else \"⚠️  REVISAR\" if acc > 0.8 else \"❌ BAJO\"\n",
    "    print(f\"{description}: {acc:.3f} {status}\")\n",
    "\n",
    "print(f\"\\nRECOMENDACIONES FINALES:\")\n",
    "print(\"1. USA el modelo conservador sin country/quality_rating\")\n",
    "print(\"2. Accuracy objetivo: 0.50-0.70 para 6 proveedores\")\n",
    "print(\"3. Prefiere modelos simples y interpretables\")\n",
    "print(\"4. Valida siempre con datos temporales\")\n",
    "print(\"5. Si accuracy > 0.80, sospecha de overfitting\")\n",
    "\n",
    "# MODELO RECOMENDADO FINAL\n",
    "print(f\"\\nMODELO RECOMENDADO PARA PRODUCCIÓN:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "final_model = DecisionTreeClassifier(\n",
    "    max_depth=3,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "accuracy_final = accuracy_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"Accuracy modelo final: {accuracy_final:.3f}\")\n",
    "print(f\"Profundidad: {final_model.get_depth()}\")\n",
    "\n",
    "# Guardar modelo recomendado\n",
    "import joblib\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "joblib.dump(final_model, '../models/decision_tree_model_fixed.pkl')\n",
    "joblib.dump(label_encoders, '../models/label_encoders_fixed.pkl')\n",
    "joblib.dump(target_encoder, '../models/target_encoder_fixed.pkl')\n",
    "joblib.dump(list(X_clean.columns), '../models/feature_names_fixed.pkl')\n",
    "\n",
    "print(f\"\\n✅ Modelo corregido guardado en ../models/*_fixed.pkl\")\n",
    "print(f\"✅ Listo para usar en sistema de recomendación\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
